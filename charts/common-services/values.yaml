# RadiantLogic Common Services Configuration
# ------------------------------------------

# This configuration defines a suite of services for managing and monitoring a RadiantLogic deployment.
# It includes tools for GitOps (Argo CD), observability (Prometheus, Grafana), log management (Elasticsearch, Kibana),
# database administration (PostgreSQL, pgAdmin), load balancing (HAProxy), and other supporting services.

# The following sections configure individual components.
# Enable or disable them as needed by setting `enabled` to `true` or `false`.

# Note: Adjust individual component settings to match your specific environment and requirements.

global:
  hibernate: false

nodeSelector: {}

# Ingress Configuration for Load Balancing
# ----------------------------------------

# This section defines an Ingress resource to manage external access to services within your Kubernetes cluster.

# Key Features:
# - `className`: Specifies the Ingress controller to use ("alb" in this case, likely for AWS Application Load Balancer).
# - `hosts`: Lists the hostnames that the Ingress should respond to.
# - `paths`: Defines the URL paths that are routed to the corresponding services.
# - `tls`: Configures TLS certificates for secure HTTPS communication (optional).

# Note: Ensure the specified Ingress controller is installed and that the TLS configuration (if used) is valid.

ingress:
  enabled: false
  className: alb
  annotations: {}
  hosts:
    - host: chart-example.local
      paths:
        - "/"
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

zookeeper:
  enabled: false
  volumePermissions:
    enabled: false
    # image:
    #  repository: radiantone/bitnami-shell
    #  tag: 11-debian-11-r51
  image:
    repository: radiantone/zookeeper
    tag: 3.8.0-debian-11-r56
  fullnameOverride: zookeeper
  nodeSelector: {}

# Argo CD Configuration
# ---------------------
#
# This section enables and configures Argo CD, a GitOps continuous delivery tool for Kubernetes.
#
# Key Features:
# - Automated application deployment and synchronization from Git repositories
# - Declarative configuration using Kubernetes manifests
# - Visual UI for managing applications and observing their state
# - Optional integration with Dex for authentication and authorization
# - Customizable server settings (root path, security)
# - Node selector configuration for different Argo CD components
#
# Note: Review and adjust settings for production environments.

argo-cd:
  enabled: true
  fullnameOverride: argocd
  configs:
    params:
      server.rootpath: "/argocd"
      server.insecure: true
    rbac:
      policy.default: 'role:readonly'
      policy.csv: |
        g, devops, role:admin
  dex:
    enabled: false
  applicationSet:
    enabled: false
  notifications:
    enabled: false
  controller:
    nodeSelector: {}
  redis:
    nodeSelector: {}
  server:
    nodeSelector: {}
    service:
      type: NodePort
  repoServer:
    nodeSelector: {}
  crds:
    keep: false
  # Disabling new components that didn't exist in 5.6.0
  commitServer:
    enabled: false
  # New required settings for 7.8.0
  redisSecretInit:
    enabled: true  #  This is needed for Redis to work properly in 7.8.0

# Prometheus Monitoring Stack Configuration
# ----------------------------------------
#
# This section enables deployment and configuration of Prometheus components:
#
# - Prometheus Server: Core time-series database for metrics collection and querying.
# - Pushgateway (Optional):  Allows ephemeral and batch jobs to expose metrics.
# - Node Exporter, Kube State Metrics, Alertmanager (Optional): Additional components for node-level metrics, Kubernetes state metrics, and alerting respectively.
#
# Key Features:
# - Customizable flags for Prometheus Server
# - Persistent storage options for Prometheus Server
# - Ability to enable/disable individual components
# - Configurable nodeSelectors for pod placement
#
# Note: Ensure correct external URL for Prometheus Server and adjust storage as needed.

prometheus:
  enabled: true
  configmapReload:
    prometheus:
      enabled: false
  # nodeExporter:
  #   enabled: false
  # kubeStateMetrics:
  #   enabled: false
  kube-state-metrics:
    enabled: false
  prometheus-node-exporter:
    enabled: true
  alertmanager:
    enabled: false
  # pushgateway:
  prometheus-pushgateway:
    fullnameOverride: prometheus-pushgateway
    nodeSelector: {}
    extraArgs:
      - "--web.enable-admin-api"
  server:
    extraFlags:
      - web.enable-lifecycle
      - web.route-prefix=/
      - web.external-url=http://prometheus-server/prometheus/
      - web.enable-admin-api
    fullnameOverride: prometheus-server
    nodeSelector: {}
    # Persistence enabled by default and size to 50Gi
    persistentVolume:
      # storageClass: "-"
      size: 8Gi
    statefulSet:
      enabled: true
    service:
      type: ClusterIP

# Grafana Configuration
# ---------------------
#
# This section deploys and configures a Grafana instance, including:
#
# - Persistent storage for dashboards and data
# - Data sources for Prometheus, Elasticsearch, Alertmanager, and OpenSearch
# - Dashboard provisioning from files (with customizable update intervals)
# - Configurable settings in `grafana.ini` (e.g., root URL, authentication)
# - Ability to override the Grafana name (`fullnameOverride`)
# - Configurable node selection and persistent storage options
# - Email (SMTP) setup for notifications (if enabled)
#
# Note: Ensure correct data source URLs and credentials. Place dashboard JSON files in the specified directories.
grafana:
  fullnameOverride: grafana
  enabled: true
  nodeSelector: {}
  service:
    type: ClusterIP
  # Persistence enabled by default
  persistence:
    enabled: true
    size: 8Gi
  grafana.ini:
    server:
      root_url: "%(protocol)s://%(domain)s/eoc-backend/grafana"
      serve_from_sub_path: true
    auth.anonymous:
      enabled: true
      org_role: Viewer
    analytics:
      check_for_updates: false
    panels:
      disable_sanitize_html: true
    log:
      mode: console
    log.console:
      format: text
      level: info
    security:
      allow_embedding: true
    smtp:
      enabled: true
      host: smtp-server:25
      from_address: saas@radiantlogic.com
    live:
      allowed_origins: "*"
  # Setup Data Source (prometheus and elastic)
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-server
          access: proxy
          isDefault: true
        - name: Elasticsearch
          type: elasticsearch
          database: vds_server_access.log*
          url: http://elasticsearch-master:9200
          password: ""
          user: ""
          access: proxy
          isDefault: false
          jsonData:
            esVersion: '7.17.3'
            logLevelField: fields.level
            logMessageField: message
            maxConcurrentShardRequests: 5
            timeField: '@timestamp'
          readonly: true
        - name: OpenSearch
          type: opensearch
          access: proxy
          isDefault: false
          url: http://opensearch-cluster-master:9200
          jsonData:
            esVersion: 70
            timeField: "@timestamp"
            interval: Daily
          readonly: true
        - name: Loki
          type: loki
          url: http://loki-gateway
          access: proxy
          isDefault: false
          # jsonData:
          #   timeout: 60
          #   maxLines: 1000

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'fid'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/fid
      - name: 'zookeeper'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/zookeeper
      - name: 'iddm'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/iddm
      - name: 'elasticsearch'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/elasticsearch
      - name: 'service-status'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/service-status
      # -- IDA Metrics Dashboards
      - name: 'ia-service-status'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-service-status
      - name: 'ida'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ida
      - name: ia-controller-beam
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-controller-beam
      - name: 'ia-controller-ecto'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-controller-ecto
      - name: 'ia-controller-oban'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-controller-oban
      - name: 'ia-controller-phoenix'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-controller-phoenix
      - name: 'ia-data-ingestion'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-data-ingestion
      - name: 'ia-extractor-webapp'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-extractor-webapp
      - name: 'ia-governance-portal'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ia-governance-portal
      # -- IDO Logs Dashboards
      - name: 'ido-logs-alert-center'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-alert-center
      - name: 'ido-logs-analytics-db'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-analytics-db
      - name: 'ido-logs-api-umbrella'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-api-umbrella
      - name: 'ido-logs-environment-setup'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-environment-setup
      - name: 'ido-logs-global-scheduler'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-global-scheduler
      - name: 'ido-logs-iddm-api-gateway'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-api-gateway
      - name: 'ido-logs-iddm-authentication-service'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-authentication-service
      - name: 'ido-logs-iddm-core'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-core
      - name: 'ido-logs-iddm-data-catalog'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-data-catalog
      - name: 'ido-logs-iddm-directory-browser'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-directory-browser
      - name: 'ido-logs-iddm-directory-namespace'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-directory-namespace
      - name: 'ido-logs-iddm-directory-schema'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-directory-schema
      - name: 'ido-logs-iddm-proxy'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-proxy
      - name: 'ido-logs-iddm-settings'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-settings
      - name: 'ido-logs-iddm-system-administration'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-system-administration
      - name: 'ido-logs-iddm-ui'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-ui
      - name: 'ido-logs-iddm-zookeeper'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-iddm-zookeeper
      - name: 'ido-logs-portal'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-portal
      - name: 'ido-logs-portal-setup'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-portal-setup
      - name: 'ido-logs-ledger-operations'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-ledger-operations
      - name: 'ido-logs-nats'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-nats
      - name: 'ido-logs-nebula-graphd'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-nebula-graphd
      - name: 'ido-logs-nebula-metad'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-nebula-metad
      - name: 'ido-logs-nebula-storaged'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-nebula-storaged
      - name: 'ido-logs-observation-supervisor'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-observation-supervisor
      - name: 'ido-logs-pipeline-job-manager'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-pipeline-job-manager
      - name: 'ido-logs-pipeline-orchestrator'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-pipeline-orchestrator
      - name: 'ido-logs-pipeline-task-manager'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-pipeline-task-manager
      - name: 'ido-logs-schema-manager'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-schema-manager
      - name: 'ido-logs-secret-manager'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-secret-manager
      - name: 'ido-logs-writeback'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-logs-writeback
      # -- IDO Metrics Dashboards
      - name: 'ido-metrics-alert-center'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-alert-center
      - name: 'ido-metrics-graph-database'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-graph-database
      - name: 'ido-metrics-iddm-core'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-iddm-core
      - name: 'ido-metrics-ido-dashboard'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-ido-dashboard
      - name: 'ido-metrics-observations-channels-contention'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-observations-channels-contention
      - name: 'ido-metrics-observations-functional'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-observations-functional
      - name: 'ido-metrics-observations-process'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-observations-process
      - name: 'ido-metrics-observations-timings'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-observations-timings
      - name: 'ido-metrics-system'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-system
      - name: 'ido-metrics-writeback-service'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards/ido-metrics-writeback-service

  dashboardsConfigMaps:
    # -- FID Dashboards
    fid: "fid-dashboard"
    zookeeper: "zookeeper-dashboard"
    iddm: "iddm-dashboard"
    elasticsearch: "audit-logs-elastic-dashboard"
    service-status: "service-status-dashboard"
    # -- IDA Metrics Dashboards
    ia-service-status: "ia-service-status-dashboard"
    ida: "ia-dashboard"
    ia-controller-beam: "ia-controller-beam-dashboard"
    ia-controller-ecto: "ia-controller-ecto-dasboard"
    ia-controller-oban: "ia-controller-oban-dashboard"
    ia-controller-phoenix: "ia-controller-phoenix-dashboard"
    ia-data-ingestion: "ia-data-ingestion-dashboard"
    ia-extractor-webapp: "ia-extractor-webapp-dashboard"
    ia-governance-portal: "ia-governance-portal-dashboard"
    # -- IDO Logs Dashboards
    ido-logs-alert-center: "ido-logs-alert-center-dashboard"
    ido-logs-analytics-db: "ido-logs-analytics-db-dashboard"
    ido-logs-api-umbrella: "ido-logs-api-umbrella-dashboard"
    ido-logs-environment-setup: "ido-logs-environment-setup-dashboard"
    ido-logs-global-scheduler: "ido-logs-global-scheduler-dashboard"
    ido-logs-iddm-api-gateway: "ido-logs-iddm-api-gateway-dashboard"
    ido-logs-iddm-authentication-service: "ido-logs-iddm-authentication-service-dashboard"
    ido-logs-iddm-core: "ido-logs-iddm-core-dashboard"
    ido-logs-iddm-data-catalog: "ido-logs-iddm-data-catalog-dashboard"
    ido-logs-iddm-directory-browser: "ido-logs-iddm-directory-browser-dashboard"
    ido-logs-iddm-directory-namespace: "ido-logs-iddm-directory-namespace-dashboard"
    ido-logs-iddm-directory-schema: "ido-logs-iddm-directory-schema-dashboard"
    ido-logs-iddm-proxy: "ido-logs-iddm-proxy-dashboard"
    ido-logs-iddm-settings: "ido-logs-iddm-settings-dashboard"
    ido-logs-iddm-system-administration: "ido-logs-iddm-system-administration-dashboard"
    ido-logs-iddm-ui: "ido-logs-iddm-ui-dashboard"
    ido-logs-iddm-zookeeper: "ido-logs-iddm-zookeeper-dashboard"
    ido-logs-portal: "ido-logs-portal-dashboard"
    ido-logs-portal-setup: "ido-logs-portal-setup-dashboard"
    ido-logs-ledger-operations: "ido-logs-ledger-operations-dashboard"
    ido-logs-nats: "ido-logs-nats-dashboard"
    ido-logs-nebula-graphd: "ido-logs-nebula-graphd-dashboard"
    ido-logs-nebula-metad: "ido-logs-nebula-metad-dashboard"
    ido-logs-nebula-storaged: "ido-logs-nebula-storaged-dashboard"
    ido-logs-observation-supervisor: "ido-logs-observation-supervisor-dashboard"
    ido-logs-pipeline-job-manager: "ido-logs-pipeline-job-manager-dashboard"
    ido-logs-pipeline-orchestrator: "ido-logs-pipeline-orchestrator-dashboard"
    ido-logs-pipeline-task-manager: "ido-logs-pipeline-task-manager-dashboard"
    ido-logs-schema-manager: "ido-logs-schema-manager-dashboard"
    ido-logs-secret-manager: "ido-logs-secret-manager-dashboard"
    ido-logs-writeback: "ido-logs-writeback-dashboard"
    # -- IDO Metrics Dashboards
    ido-metrics-alert-center: "ido-metrics-alert-center-dashboard"
    ido-metrics-graph-database: "ido-metrics-graph-database-dashboard"
    ido-metrics-iddm-core: "ido-metrics-iddm-core-dashboard"
    ido-metrics-ido-dashboard: "ido-metrics-ido-dashboard-dashboard"
    ido-metrics-observations-channels-contention: "ido-metrics-observations-channels-contention-dashboard"
    ido-metrics-observations-functional: "ido-metrics-observations-functional-dashboard"
    ido-metrics-observations-process: "ido-metrics-observations-process-dashboard"
    ido-metrics-observations-timings: "ido-metrics-observations-timings-dashboard"
    ido-metrics-system: "ido-metrics-system-dashboard"
    ido-metrics-writeback-service: "ido-metrics-writeback-service-dashboard"

# Elasticsearch & Kibana Configuration
# -----------------------------------
#
# This section enables deployment of an Elasticsearch cluster and Kibana for log management and visualization.
#
# Key Features:
# - Single-node Elasticsearch cluster (customizable replica count)
# - Persistent storage for Elasticsearch data
# - Kibana instance with customizable base path and telemetry settings
# - Configurable node selectors for pod placement
#
# Important Considerations:
# - Adjust storage size (`volumeClaimTemplate.resources.requests.storage`) to match your needs.
# - Modify `clusterHealthCheckParams` based on your cluster's expected health status and timeout.

elasticsearch:
  enabled: true
  replicas: 1
  nodeSelector: {}
  service:
    type: ClusterIP
  # Persistence enabled by default and size to 100Gi
  volumeClaimTemplate:
    resources:
      requests:
        storage: 30Gi
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=60s"
  # enable authentication
  # esMajorVersion: 6
  # minimumMasterNodes: 1
  # esConfig:
  #   elasticsearch.yml: |
  #     xpack.security.enabled: true
  #     discovery.type: single-node
  # extraEnvs:
  #   - name: ELASTIC_PASSWORD
  #     value: changeme

kibana:
  enabled: true
  fullnameOverride: kibana
  nodeSelector: {}
  service:
    type: ClusterIP
  # extraEnvs:
  #   - name: ELASTICSEARCH_USERNAME
  #     value: elastic
  #   - name: ELASTICSEARCH_PASSWORD
  #     value: changeme
  healthCheckPath: "/eoc-backend/kibana"
  kibanaConfig:
    kibana.yml: |
      server.basePath: "/eoc-backend/kibana"
      server.publicBaseUrl: http://kibana.{{ .Release.Namespace }}.svc.cluster.local:5601/eoc-backend/kibana
      telemetry.optIn: false
      security.showInsecureClusterWarning: false
      server.rewriteBasePath: true
      server.compression.enabled: true
      server.requestId.allowFromAnyIp: true

# HAProxy Configuration
# ---------------------
#
# This section configures HAProxy as an API gateway for internal services.
# It provides:
#   - Load balancing and routing for enabled services
#   - Basic security headers and connection timeouts
#   - Stats and health check endpoints
#   - Customization through the 'route' section (toggle services on/off)
#   - Fine-grained backend configuration using templating
#
# Note: Ensure correct service names and ports in the backend definitions.
haproxy:
  enabled: true
  route:
    argocd: true
    grafana: true
    prometheus: false
    pushgateway: false
    elasticsearch: false
    kibana: true
    pgadmin4: false
    slamd: false
    shellinabox: false
    eocui: false
    eocapi: false
    sdcapi: false
    opensearch: false
    opensearchdashboards: false

  fullnameOverride: haproxy
  nodeSelector: {}
  service:
    type: NodePort
  config: |
    defaults
      timeout connect 10s
      timeout client 30s
      timeout server 30s
      log global
      mode http
      option httplog
      maxconn 3000
    frontend http-in
      bind *:80

      stats enable
      stats refresh 30s
      stats show-node
      stats uri /stats
      monitor-uri /healthz
      {{- if ((.Values.route).eocui | default false) }}
      default_backend def_backend
      {{- end }}

      # Remove unnecessary headers
      http-response del-header Server
      http-response del-header X-Powered-By
      http-response del-header X-AspNetMvc-Version
      http-response del-header X-AspNet-Version
      http-response del-header X-Drupal-Cache
      http-response del-header X-Drupal-Dynamic-Cache
      http-response del-header X-Generator
      http-response del-header X-Runtime
      http-response del-header X-Rack-Cache

      # Add security headers
      http-response set-header Strict-Transport-Security "max-age=16000000; includeSubDomains; preload;"
      http-response set-header X-Frame-Options "SAMEORIGIN"
      http-response set-header X-Content-Type-Options "nosniff"
      http-response set-header Referrer-Policy no-referrer-when-downgrade
      http-response set-header X-XSS-Protection 1;mode=block
      http-response set-header Permissions-Policy interest-cohort=()


      # routing
      {{- if ((.Values.route).argocd | default false) }}
      use_backend argocd_backend if { path /argocd } or { path_beg /argocd/ }
      {{- end }}
      {{- if ((.Values.route).grafana | default false) }}
      use_backend grafana_backend if { path /grafana } or { path_beg /grafana/ }
      {{- end }}
      {{- if ((.Values.route).prometheus | default false) }}
      use_backend prometheus_backend if { path /prometheus } or { path_beg /prometheus/ }
      {{- end }}
      {{- if ((.Values.route).pushgateway | default false) }}
      use_backend pushgateway_backend if { path /pushgateway } or { path_beg /pushgateway/ }
      {{- end }}
      {{- if ((.Values.route).kibana | default false) }}
      use_backend kibana_backend if { path /kibana } or { path_beg /kibana/ }
      {{- end }}
      {{- if ((.Values.route).elasticsearch | default false) }}
      use_backend elasticsearch_backend if { path /elasticsearch } or { path_beg /elasticsearch/ }
      {{- end }}
      {{- if ((.Values.route).pgadmin4 | default false) }}
      use_backend pgadmin4_backend if { path /pgadmin4 } or { path_beg /pgadmin4/ }
      {{- end }}
      {{- if ((.Values.route).slamd | default false) }}
      use_backend slamd_backend if { path /slamd } or { path_beg /slamd/ }
      {{- end }}
      {{- if ((.Values.route).shellinabox | default false) }}
      use_backend shellinabox_backend if { path /shellinabox } or { path_beg /shellinabox/ }
      {{- end }}
      {{- if ((.Values.route).eocui | default false) }}
      use_backend eocui_backend if { path /eoc } or { path_beg /eoc/ }
      {{- end }}
      {{- if ((.Values.route).eocapi | default false) }}
      use_backend eocapi_backend if { path /eoc-backend } or { path_beg /eoc-backend/ }
      {{- end }}
      {{- if ((.Values.route).sdccui | default false) }}
      use_backend sdcapi_backend if { path /sdc } or { path_beg /sdc/ }
      {{- end }}
      {{- if ((.Values.route).opensearchdashboards | default false) }}
      use_backend opensearchdashboards_backend if { path /opensearch-dashboards } or { path_beg /opensearch-dashboards/ }
      {{- end }}
      {{- if ((.Values.route).opensearch | default false) }}
      use_backend opensearch_backend if { path /opensearch } or { path_beg /opensearch/ }
      {{- end }}
      {{- if ((.Values.route).velero | default false) }}
      use_backend velero_backend if { path /velero } or { path_beg /velero/ }
      {{- end }}

    # backends
    {{- if ((.Values.route).argocd | default false) }}
    backend argocd_backend
      server argocd argocd-server:80 check
    {{- end }}
    {{- if ((.Values.route).grafana | default false) }}
    backend grafana_backend
      http-request set-path %[path,regsub(^/grafana/?,/)]
      server grafana grafana:80 check
    {{- end }}
    {{- if ((.Values.route).prometheus | default false) }}
    backend prometheus_backend
      http-request set-path %[path,regsub(^/prometheus/?,/)]
      server prometheus prometheus-server:80 check
    {{- end }}
    {{- if ((.Values.route).pushgateway | default false) }}
    backend pushgateway_backend
      http-request set-path %[path,regsub(^/pushgateway/?,/)]
      server pushgateway prometheus-pushgateway:9091 check
    {{- end }}
    {{- if ((.Values.route).kibana | default false) }}
    backend kibana_backend
      http-request set-path %[path,regsub(^/kibana/?,/)]
      server kibana kibana:5601 check
    {{- end }}
    {{- if ((.Values.route).elasticsearch | default false) }}
    backend elasticsearch_backend
      http-request set-path %[path,regsub(^/elasticsearch/?,/)]
      server elasticsearch elasticsearch-master:9200 check
    {{- end }}
    {{- if ((.Values.route).pgadmin4 | default false) }}
    backend pgadmin4_backend
      server pgadmin4 pgadmin4:80 check
    {{- end }}
    {{- if ((.Values.route).slamd | default false) }}
    backend slamd_backend
      server slamd slamd:80 check
    {{- end }}
    {{- if ((.Values.route).shellinabox | default false) }}
    backend shellinabox_backend
      http-request set-path %[path,regsub(^/shellinabox/?,/)]
      server shellinabox shellinabox:8080 check
    {{- end }}
    {{- if ((.Values.route).eocui | default false) }}
    backend eocui_backend
      server eocui eoc-ui-service:80 check
    {{- end }}
    {{- if ((.Values.route).eocapi | default false) }}
    backend eocapi_backend
      server eocapi eoc-backend-service:80 check
    {{- end }}
    {{- if ((.Values.route).sdccui | default false) }}
    backend sdcapi_backend
      server sdcapi sdc-agent:80 check
    {{- end }}
    {{- if ((.Values.route).opensearchdashboards | default false) }}
    backend opensearchdashboards_backend
      #http-request set-path %[path,regsub(^/opensearch-dashboards/?,/)]
      server opensearchdashboards opensearch-dashboards:5601 check
    {{- end }}
    {{- if ((.Values.route).opensearch | default false) }}
    backend opensearch_backend
      http-request set-path %[path,regsub(^/opensearch/?,/)]
      server opensearch opensearch-cluster-master:9200 check
    {{- end }}
    {{- if ((.Values.route).velero | default false) }}
    backend velero_backend
      http-request set-path %[path,regsub(^/velero/?,/)]
      server velero velero-ui:3000 check
    {{- end }}
    {{- if ((.Values.route).eocui | default false) }}
    # Default backend
    backend def_backend
      http-request redirect code 301 location /eoc
      server eocui eoc-ui-service:80 check
    {{- end }}

# PostgreSQL Database Configuration
# ---------------------------------
#
# This section enables deployment and configuration of a PostgreSQL database cluster.
#
# Key Features:
# - Single-node PostgreSQL deployment (can be expanded in more advanced scenarios)
# - Persistent storage for database data
# - Customizable initialization scripts via ConfigMap
# - Predefined databases for EOC and SDC applications
# - Option to configure backups to S3 (commented out by default)
#
# Important Considerations:
# - Adjust storage size (`persistence.size`) to match your needs.
# - Securely manage database credentials (e.g., using Kubernetes Secrets).
# - If enabling backups, ensure proper S3 configuration and credentials.

postgresql:
  enabled: true
  volumePermissions:
    enabled: false
    # image:
    #  repository: radiantone/bitnami-shell
    #  tag: 11-debian-11-r57
  metrics:
    enabled: false
    # image:
    #  repository: radiantone/postgres-exporter
    #  tag: 0.11.1-debian-11-r34
  fullnameOverride: postgresql
  image:
    repository: radiantone/postgresql
    tag: 15.1.0-debian-11-r7
  primary:
    nodeSelector: {}
    service:
      type: ClusterIP
    # Persistence enabled by default and size to 50Gi
    persistence:
      size: 10Gi
    initdb:
      scriptsConfigMap: "postgres-init-script"
  databases:
    eoc:
      databaseName: eocdb
      user: eocadmin
      password: TSXojYsPF4AeZgTq
      schema: eoc
    sdc:
      databaseName: agentsdb
      user: agentsadmin
      password: iJukleKLG9fNihIQ
      schema: agents
  # backup:
    # enabled: false
    # s3bucketName: ""
    # folderName: "postgresql"
    # latestBackupName: "postgresql-latest.sql.gz"

# pgAdmin4 Configuration
# ----------------------
#
# This section enables deployment of pgAdmin4, a web-based administration tool for PostgreSQL databases.
#
# Key Features:
# - Single-pod deployment of pgAdmin4
# - Configurable context path for web access
# - Option to enable persistent storage for configuration data
# - Customizable node selection for pod placement
#
# Note: Persistent storage is disabled by default. Enable it if you need to preserve pgAdmin4 configuration data across pod restarts.

pgadmin4:
  enabled: true
  fullnameOverride: pgadmin4
  nodeSelector: {}
  service:
    type: ClusterIP
  persistentVolume:
    enabled: false
  env:
    contextPath: "/pgadmin4"

# SLAMD Configuration
# --------------------
#
# This section enables deployment of SLAMD, a tool for load testing and benchmarking LDAP directories.
#
# Key Features:
# - Deploy SLAMD server and optionally client instances
# - Customize image versions and pull policies
# - Configure pod and container security settings
# - Define resource requests and limits for SLAMD components
# - Optionally enable autoscaling based on CPU utilization
# - Configure node selectors, tolerations, and affinity for pod placement
#
# Note: Review and adjust settings according to your testing requirements.

slamd:
  enabled: true
  replicaCount: 1
  image:
    repository: pgodey/slamd
    pullPolicy: IfNotPresent
    tag: "latest"
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  service:
    type: ClusterIP
    port: 80
  resources: {}
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  nodeSelector: {}
  tolerations: []
  affinity: {}

  client:
    replicaCount: 0
    image:
      repository: pgodey/slamd-client
      pullPolicy: IfNotPresent
      tag: "latest"
    podAnnotations: {}
    podSecurityContext: {}
    # fsGroup: 2000
    securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
    resources: {}
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 100
      targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
    nodeSelector: {}
    tolerations: []
    affinity: {}

# Shellinabox Configuration
# ------------------------
#
# This section enables deployment of Shellinabox, a web-based SSH terminal emulator.
#
# Key Features:
# - Single-pod deployment of Shellinabox
# - Customizable Docker image repository and tag
# - Configurable service type and port for access
# - Optional settings for pod and container security
# - Resource management options for CPU and memory
# - Node selection, tolerations, and affinity controls for pod scheduling
#
# Note: Review and adjust security settings based on your environment's requirements.

shellinabox:
  enabled: false
  replicaCount: 1
  image:
    repository: sspreitzer/shellinabox
    pullPolicy: IfNotPresent
    tag: "ubuntu"
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  service:
    type: ClusterIP
    port: 8080
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

# SMTP Relay Configuration
# ------------------------
#
# This section enables deployment of an SMTP relay container to send emails from within the Kubernetes cluster.
#
# Key Features:
# - Single-pod deployment of SMTP relay
# - Configurable SMTP relay host, port, and authentication credentials
# - Customizable Docker image repository and tag
# - Configurable service type and port for access
# - Optional settings for pod and container security
# - Resource management options for CPU and memory
# - Node selection, tolerations, and affinity controls for pod scheduling
#
# Note: Ensure correct SMTP relay credentials and adjust security settings based on your environment's requirements.

smtp:
  enabled: true
  replicaCount: 1
  image:
    repository: bytemark/smtp
    tag: "latest"
    pullPolicy: IfNotPresent
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
  service:
    type: ClusterIP
    port: 8080
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  relay:
    enabled: true
    host: "smtp.sendgrid.net"
    port: "587"
    username: ""
    password: ""

# OpenSearch Configuration
# ------------------------
# This section controls the deployment of an OpenSearch cluster and its accompanying dashboard.
#
# Key Settings:
#   - `enabled`: Set to `true` to deploy OpenSearch (and optionally OpenSearch Dashboards).
#   - `singleNode`: If `true`, a single-node cluster is created for development/testing.
#   - `replicas`: Number of data replicas for each primary shard (for high availability and scalability).
#   - `persistence.size`: Size of the persistent volume for storing OpenSearch data.

opensearch:
  enabled: false
  fullnameOverride: "opensearch"
  singleNode: true
  replicas: 1
  clusterName: "opensearch-cluster"
  nodeGroup: "master"
  masterService: "opensearch-cluster-master"
  extraEnvs:
    - name: "DISABLE_SECURITY_PLUGIN"
      value: "true"
    - name: "DISABLE_INSTALL_DEMO_CONFIG"
      value: "true"
  rbac:
    create: false
    serviceAccountAnnotations: {}
    serviceAccountName: ""
  nodeSelector: {}
  persistence:
    size: 30Gi
  podSecurityContext:
    fsGroup: 1000
    runAsUser: 1000
  service:
    type: ClusterIP
    nodePort: ""
    annotations: {}
    httpPortName: http
    transportPortName: transport

opensearch-dashboards:
  enabled: false
  opensearchHosts: "http://opensearch-cluster-master:9200"
  replicaCount: 1
  fullnameOverride: "opensearch-dashboards"
  extraEnvs:
    - name: DISABLE_SECURITY_DASHBOARDS_PLUGIN
      value: "true"
  service:
    type: ClusterIP
    port: 5601
    loadBalancerIP: ""
    nodePort: ""
    labels: {}
    annotations: {}
    loadBalancerSourceRanges: []
    # 0.0.0.0/0
    httpPortName: http
  nodeSelector: {}
    # tenantname: duploservices-nike-svc
  plugins:
    enabled: false
    installList: []
  config:
    opensearch_dashboards.yml: |
      server:
        basePath: "/opensearch-dashboards"
        rewriteBasePath: true

# Fluent Bit Configuration
# ------------------------
# This section controls the deployment and configuration of Fluent Bit, a lightweight and high-performance log processor and forwarder.

# Enable/Disable Fluent Bit: Set `enabled` to `true` to deploy Fluent Bit.
# Node Selection (Optional): Use `nodeSelector` to schedule Fluent Bit pods onto specific nodes.
# Log Sources (Required): Define a list of log sources that Fluent Bit should collect.
#    - For each source, specify:
#        - `name`: A descriptive name for the log source.
#        - `enable`: Whether to collect logs from this source (`true` or `false`).
#        - `path`: The path to the log files (use wildcards like `*`).
#        - `refresh_interval`: How often Fluent Bit checks for new log data (in seconds).
# Output Destination (Required): Configure where Fluent Bit should send the collected logs.
#    - `outputSearchHost`: Hostname or IP of your Elasticsearch (or OpenSearch) cluster.
#    - `outputSearchType`:  Choose either "es" for Elasticsearch or "opensearch".
# Fluent Bit Configuration (Optional): Fine-tune Fluent Bit's behavior.
#    - `fullnameOverride`: Customize the name of Fluent Bit resources (e.g., DaemonSet).
#    - `flush`: How often Fluent Bit sends logs to the output destination (in seconds).
#    - `logLevel`:  Logging verbosity ("info", "debug", etc.).
#    - `metricsPort`: Port for exposing Fluent Bit metrics.
# Service (Optional): Expose Fluent Bit's metrics or other ports via a Kubernetes Service.
# Monitoring (Optional):
#    - `prometheusRule`: Enable to create a PrometheusRule for Fluent Bit metrics.
#    - `serviceMonitor`: Enable to create a ServiceMonitor to scrape Fluent Bit metrics with Prometheus Operator.
# Existing ConfigMap (Optional): If you have a pre-existing ConfigMap with custom Fluent Bit configuration, specify its name here.

fluent-bit:
  enabled: false
  nodeSelector: {}
    # tenantname:
  fullnameOverride: "fluent-bit"
  existingConfigMap: fluent-bit-config
  flush: 1
  logLevel: info
  metricsPort: 2020
  service:
    type: ClusterIP
  prometheusRule:
    enabled: false
  serviceMonitor:
    enabled: false
# ====== For helm chart version < 1.0.9 =====
  outputSearchType: "es"
  outputSearchHost: "elasticsearch-master"
  # outputSearchPort: 9200
  # outputSearchTLS: false
  # outputSearchTLSVerify: true
  # outputSearchUsername: "elastic"
  # outputSearchPassword: "changeme"
# =========================================
  logs:
    - name: eoc-backend
      enable: true
      path: /var/log/containers/eoc-backend-*.log
      refresh_interval: 10
      aggregators: ["elasticsearch"]
    - name: eoc-orchestrator
      enable: true
      path: /var/log/containers/eoc-orchestrator-*.log
      refresh_interval: 10
      aggregators: ["elasticsearch"]
    - name: sdc
      enable: true
      path: /var/log/containers/sdc-*.log
      refresh_interval: 10
      aggregators: ["elasticsearch"]
    - name: client-router
      enable: true
      path: /var/log/containers/client-*.log
      refresh_interval: 10
      aggregators: ["elasticsearch"]
    - name: tunnel
      enable: true
      path: /var/log/containers/r1tunnel*.log
      refresh_interval: 10
      aggregators: ["elasticsearch"]
# ====== For helm chart version >= 1.0.9 =====
  aggregators: []
    # - type: es  # Elasticsearch output plugin
    #   host: "elasticsearch-master"
    #   port: 9200
    #   index_prefix: "es-index"
    #   tls: false
    #   name: "elasticsearch"
    #   username: "elastic"
    #   password: "changeme"
    # - type: splunk  # Splunk output plugin
    #   host: "splunk-master"
    #   port: 8088
    #   splunk_token: "your-splunk-token"
    #   index_prefix: "splunk-index"
    #   tls: true
    #   tls_verify: false
    #   name: "splunk"
    # - type: opensearch  # OpenSearch output plugin
    #   host: "opensearch-cluster-master"
    #   port: 9200
    #   index_prefix: "opensearch-index"
    #   tls: false
    #   name: "opensearch"
    #   username: "admin"
    #   password: "admin"

# Curator Configuration
# --------------------
# This section controls the behavior of Elasticsearch Curator, a tool for managing Elasticsearch indices.
# Curator can perform actions like deleting, closing, or creating indices based on configured filters.

curator:
  image:
    repository: radiantone/elasticsearch-curator-archived
    pullPolicy: Always
    tag: 5.8.4-debian-10-r253
  imagePullSecrets: []
  enabled: true
  dryrun: false
  # Elasticsearch Client Settings
  # -----------------------------
  # Specify the connection details for your Elasticsearch cluster.
  client:
    hosts: ["elasticsearch-master"]
    port: 9200
    use_ssl: false
    ssl_no_validate: true
    timeout: 300
    certificate: ""
    client_cert: ""
    client_key: ""
    # set username for es authentication
    username: ""
    # set password for es authentication
    password: ""
    master_only: false
  logging:
    # Curator Logging Configuration
    # ------------------------------
    # Customize how Curator logs its activities.
    # Set the desired log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    loglevel: "INFO"
    logfile: ""
    logformat: "default"
    blacklist: ['elasticsearch', 'urllib3']
# Index Management Actions
# -------------------------
# Define a list of actions to be performed on Elasticsearch indices.
# Each action can have filters to select specific indices based on name patterns or age.
  logs:
    - name: "vds_server.log"
      # action: "delete_indices"
      # description: "Delete vds_server log files"
      # unit_count: 30
      # timeout_override: "120s"
    - name: "vds_server_access.log"
    - name: "adap_access.log"
    - name: "adap.log"
    - name: "web.log"
    - name: "web_access.log"
    - name: "vds_events.log"
    - name: "periodiccache.log"
    - name: "admin_rest_api_access.log"
    - name: "sync_engine.log"
    - name: "alerts.log"
    - name: "approvals_audit.log"
    - name: "scim.log"
    - name: "audit.log"
    - name: "internal-container.log"
    - name: "zookeeper.log"
    - name: "ia_batch_timing.log"
    - name: "ia_extractor.log"
    - name: "ia_init_database.log"
    - name: "ia_portal_access.log"
    - name: "ia_portal_application.log"
    - name: "ia_portal_login.log"
    - name: "ia_portal_monitoring.log"
    - name: "ia_git_service.log"
    # - name: "close-old-indices"
    #   action: "close"
    #   description: "Close indices older than a year"
    #   delete_aliases: false
    #   skip_flush: true
    #   ignore_sync_failures: true
    #   timeout_override: "60s"
    #   value: "old-"
    #   unit: "months"
    #   unit_count: 12
    #   direction: "older"
    # - name: "create-new-index"
    #   action: "create_index"
    #   description: "Create a new index for upcoming logs"
    #   extra_settings:
    #     settings:
    #       number_of_shards: 3
    #       number_of_replicas: 1
    #   unit: "days"
    #   unit_count: 1
  cronjob:
    # Curator Cron Job Settings
    # --------------------------
    # Configure the Kubernetes CronJob that will trigger Curator actions.
    # Cron schedule (e.g., every day)
    schedule: "0 0 * * *"
    annotations: {}
    labels: {}
    concurrencyPolicy: ""
    failedJobsHistoryLimit: ""
    successfulJobsHistoryLimit: ""
    jobRestartPolicy: Never
    startingDeadlineSeconds: ""
  pod:
    annotations: {}
  rbac:
    enabled: false
  serviceAccount:
    create: false
    annotations: {}
  hooks:
    install: false
    upgrade: false
  priorityClassName: ""
  securityContext:
    runAsUser: 16
  psp:
    create: false
  resources: {}
  nodeSelector: {}
    # tenantname:

# Velero Backup and Disaster Recovery Configuration
# ------------------------------------------------
#
# This section enables deployment of Velero, a Kubernetes backup and disaster recovery tool.
#
# Key Features:
# - Backup and restore Kubernetes resources and persistent volumes
# - Scheduled backups with configurable frequency and retention policies
# - Support for various backup storage providers (e.g., AWS S3, Azure Blob Storage, etc.)
# - Plugin system for extending functionality
#
# Key Configuration:
# - `backupStorage`: Define the storage location for backups (e.g., S3 bucket).
# - `credentials`: Configure credentials for the backup storage provider (if needed).
# - `defaultBackupTTL`: Set the default retention period for backups.
#
# Note: Ensure proper configuration of backup storage and credentials for successful operation.

velero:
  enabled: false
  fullnameOverride: "velero"
  backupStorage:
    bucket: ""
    region: ""
    # defines how frequently Velero should validate the object storage
    validationFrequency: 1h
    # prefix is the directory under which all Velero data should be stored within the bucket
    prefix:
  credentials:
    useSecret: false
  cleanUpCRDs: true
  upgradeCRDs: false
  nodeSelector: {}
  kubectl:
    image:
      repository: docker.io/radiantone/kubectl
  configuration:
    # defaultBackupStorageLocation: common-bsl
    # defaultVolumeSnapshotLocations: common-vsl
    # how long to wait by default before backups can be garbage collected
    defaultBackupTTL: 168h
    # the frequency of the reconciliation loop that garbage the expired backups
    garbageCollectionFrequency: 1h
    # avoid default Backup Storage Location to be created by Velero chart
    backupStorageLocation: []
    # avoid default Volume Storage Location to be created by Velero chart
    volumeSnapshotLocation: []
  initContainers:
    - name: velero-plugin-for-aws
      # image: "velero/velero-plugin-for-aws:v1.11.1"
      image: "velero/velero-plugin-for-aws:v1.12.2"
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: /target
          name: plugins

# Zoo Navigator Configuration
# ----------------------------
#
# This section enables deployment of Zoo Navigator, a web-based tool for visualizing and managing Apache ZooKeeper clusters.
#
# Key Features:
# - Single-pod deployment of Zoo Navigator
# - Configurable Docker image repository, tag, and pull policy
# - Service definition for exposing Zoo Navigator to the network
# - Optional settings for pod and container security
# - Resource limits and requests for CPU and memory
# - Optional horizontal autoscaling based on CPU/memory utilization
# - Node selector, tolerations, and affinity controls for pod scheduling
#
# Note: Review and adjust settings according to your ZooKeeper cluster setup and requirements.

zoonavigator:
  enabled: false
  replicaCount: 1
  image:
    repository: elkozmon/zoonavigator
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  service:
    type: ClusterIP
    port: 80
  resources: {}
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  nodeSelector: {}
  tolerations: []
  affinity: {}

# -----------------------------------------------------------------
# -- Cloud Native PG
# -----------------------------------------------------------------
cloudnative-pg:
  enabled: false
  fullnameOverride: cnpg
  config:
    create: true
    name: cnpg-controller-manager-config
    data:
      INHERITED_LABELS: app.kubernetes.io/*, radiantlogic.io/*, *.radiantlogic.io/*
      INHERITED_ANNOTATIONS: meta.helm.sh/*, helm.sh/*, radiantlogic.io/*, *.radiantlogic.io/*
  nodeSelector: {}
  tolerations: []
  affinity: {}
  # CRDs are installed by a dedicated job
  crds:
    create: false

# -----------------------------------------------------------------
# -- Identity Observability - Nebula Operator for Graph Database
# -----------------------------------------------------------------
nebula-operator:
  enabled: false
  nameOverride: nebula
  imagePullSecrets: []

  controllerManager:
    replicas: 1

  scheduler:
    replicas: 1

  admissionWebhook:
    contollerManagerAdmissionWebhook:
      create: false
    autoscalerAdmissionWebhook:
      create: false

  # -- don't use Nebula provided job to avoid any issue with ArgoCD
  upgradeCRD: false

  nodeSelector: {}
  tolerations: []
  affinity: {}

# -----------------------------------------------------------------
# -- Identity Observability - Flink Operator for Apache Flink data processor
# -----------------------------------------------------------------
flink-kubernetes-operator:
  enabled: false
  fullnameOverride: flink-operator
  nameOverride: flink-operator
  imagePullSecrets: []
  operatorPod:
    nodeSelector: {}

  webhook:
    create: false

  jobServiceAccount:
    create: true
    annotations: {}
    name: "flink"

# -----------------------------------------------------------------
# -- Backup Manager service for Velero
# -----------------------------------------------------------------
backupManager:
  enabled: false
  replicas: 1
  image:
    repository: radiantone/eoc-backup-manager
    tag: "1.16.0"
    pullPolicy: Always
  imagePullSecrets: []
  service:
    port: 80
    containerPort: 8080
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      cpu: "250m"
      memory: 512Mi
    requests:
      cpu: "250m"
      memory: 256Mi
  nodeSelector: {}
  tolerations: []
  affinity: {}
  log:
    format: text
    level: info
  swagger:
    enabled: false
    host: localhost
    port: 8080
  podsWaitTimeout: "5m"
  webhook:
    enabled: false
    syncPeriod: "1m"
    backup:
      # Ex. http://eoc-backend-service/webhook/backups
      url: ""
      timeout: "1h"
    restore:
      # Ex. http://eoc-backend-service/webhook/restores
      url: ""
      timeout: "1h"

# -----------------------------------------------------------------
# -- Velero UI -- from https://github.com/otwld/velero-ui
# -----------------------------------------------------------------
velero-ui:
  enabled: false
  env:
    - name: BASIC_AUTH_PASSWORD
      value: "eLm0p#u6Fk"
  fullnameOverride: "velero-ui"
  nodeSelector: {}
  service:
    type: NodePort
  configuration:
    general: {}
      # veleroNamespace: velero

# -----------------------------------------------------------------
# Loki -- https://grafana.com/docs/loki/latest/setup/install
# https://github.com/grafana/loki/blob/main/production/helm/loki/
# -----------------------------------------------------------------
loki:
  enabled: false
  fullnameOverride: loki

  deploymentMode: SimpleScalable
  imagePullSecrets: []

  test:
    enabled: false
  lokiCanary:
    enabled: false
  ruler:
    enabled: false

  loki:
    # multi-tenancy disabled by default
    auth_enabled: false
    schemaConfig:
      configs:
        - from: "2024-04-01"
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h

    storage_config:
      aws: {}
        # region: eu-west-3
        # bucketnames: duploservices-rli-ops10-svc-common-125328463501
        # s3forcepathstyle: true

    ingester:
      chunk_encoding: snappy
      wal:
        enabled: true
        flush_on_shutdown: true

    querier:
      # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
      max_concurrent: 4

    pattern_ingester:
      enabled: true

    # Global limit for all tenants (can be overriden per tenant)
    limits_config:
      allow_structured_metadata: true
      volume_enabled: true
      # 1 day retention (minimal retention is 24h)
      retention_period: 24h
      # Example use of label to dynamically control retention
      # retention_stream:
      #   - selector: '{retention_policy="7d"}'
      #     priority: 1
      #     # 7 days
      #     period: 168h
      #   - selector: '{retention_policy="30d"}'
      #     priority: 1
      #     # 30 days
      #     period: 720h
      #   - selector: '{retention_policy="90d"}'
      #     priority: 1
      #     # 90 days
      #     period: 2160h
      #   - selector: '{environment_type="ephemeral"}'
      #     priority: 1
      #     period: 24h
      #   - selector: '{log_level="error"}'
      #     priority: 2
      #     period: 2160h

    compactor:
      retention_enabled: true
      retention_delete_delay: 1h
      delete_request_store: s3

    storage:
      type: s3
      bucketNames: {}
        # chunks: duploservices-rli-ops10-svc-common-125328463501
        # ruler: duploservices-rli-ops10-svc-common-125328463501
        # admin: duploservices-rli-ops10-svc-common-125328463501
      s3: {}
        # region: eu-west-3
        # s3forcepathstyle: true

  chunksCache:
    replicas: 1
    nodeSelector: {}

  gateway:
    replicas: 1
    # Disable logging of 2xx and 3xx HTTP requests
    verboseLogging: false
    nodeSelector: {}

  backend:
    replicas: 3
    persistence:
      # Usage:
      #   - Local Temporal (TSDB) Index: index cache for faster queries
      #   - Local Compaction Cache: temporary data during compaction
      #   - Local Alerting Rules: if you use the ruler
      # Dimensionnement :
      #   - Temporal (TSDB) Index Cache: ~10% of total index volume
      #   - Compaction Cache: space for compaction
      #   - Formule : (daily_ingestion_gb * retention_days * 0.1) + working_space
      #  Example:
      #  - 30GB daily ingestion  30 days retention  0.1 = 90GB minimum
      size: 100Gi
    nodeSelector: {}

  read:
    replicas: 3
    nodeSelector: {}

  write:
    replicas: 3
    persistence:
      # Usage:
      #   - Write-Ahead Log (WAL): ensure data durability before pushing to S3
      #   - Active Temporal (TSDB) Index: index of recent data not yet sent to S3
      #   - Temporary Chunks: temporary data during aggregation before sending to S3
      # Size based on:
      #  - Ingestion Volume: ~5MB/s = 15GB WAL on average
      #  - Safety Factor: x3 for peaks
      #  - Formula: (ingestion_rate_mb * flush_interval_seconds * safety_factor) + overhead
      #  Example:
      #   - 20MB/s ingestion  300s flush  3 = 18GB minimum
      #   - Recommendation: 50GB for comfort
      size: 50Gi
    nodeSelector: {}

# -----------------------------------------------------------------
# Alloy
#   https://grafana.com/docs/loki/latest/send-data/alloy/
#   https://github.com/grafana/alloy/tree/main/operations/helm/charts/alloy
# -----------------------------------------------------------------
alloy:
  enabled: false
  fullnameOverride: alloy

  image:
    pullSecrets: []

  # Do not install CRDs for monitoring
  crds:
    create: false

  loki:
    # example: http://loki-gateway.duploservices-rli-ops10-svc.svc.cluster.local/loki/api/v1/push
    url: ""

  staticLabels: {}
    # cluster: "rli-ops10"
    # region: "eu-west-3"

  alloy:
    mounts:
      varlog: true
      dockercontainers: false
    # 1. discovery.kubernetes  Discover pods matching criteria
    #                        
    # 2. discovery.relabel    Filter according to your criteria
    #                        
    # 3. loki.source         Read log files
    #                        
    # 4. loki.process        Parse, assign tenant, optimize
    #                        
    # 5. loki.write          Send to Loki with correct tenant
    configMap:
      content: |
        logging {
          level  = "info"
          format = "logfmt"
        }

        livedebugging {
          enabled = false
        }

        // ========== List tenant pods ==========
        discovery.kubernetes "tenant_pods" {
          role = "pod"
          selectors {
            role = "pod"
            // Only application pods (with label "radiantlogic.io/environment")
            label = "radiantlogic.io/environment"
          }
          // selectors {
          //   role = "pod"
          //   // Only application pods (with label "logging.radiantlogic.io/enabled=true")
          //   label = "logging.radiantlogic.io/enabled=true"
          // }
        }

        discovery.relabel "filtered_pods" {
          targets = discovery.kubernetes.tenant_pods.targets

          rule {
            source_labels = ["__meta_kubernetes_pod_annotation_logging_radiantlogic_io_enabled"]
            regex = "true"
            action = "keep"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_annotation_logging_radiantlogic_io_retention_policy"]
            regex = "(1d|7d|30d|90d|1y)"
            target_label = "retention_policy"
          }

          rule {
            source_labels = ["retention_policy"]
            regex = "^$"
            replacement = "7d"
            target_label = "retention_policy"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_radiantlogic_io_environment"]
            target_label = "tenant"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_radiantlogic_io_environment"]
            target_label  = "environment"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_radiantlogic_io_environment_type"]
            regex = "(ephemeral|dev|qa|non-prod|prod)"
            target_label = "environment_type"
          }

          rule {
            source_labels = ["environment_type"]
            regex = "^$"
            replacement = "non-prod"
            target_label = "environment_type"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_controller_name"]
            regex         = "([0-9a-z-.]+?)(-[0-9a-f]{8,10})?"
            target_label  = "__tmp_controller_name"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_radiantlogic_io_app", "__meta_kubernetes_pod_label_app_kubernetes_io_name", "__meta_kubernetes_pod_label_app", "__tmp_controller_name", "__meta_kubernetes_pod_name"]
            regex         = "^;*([^;]+)(;.*)?$"
            target_label  = "app"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_instance", "__meta_kubernetes_pod_label_instance"]
            regex         = "^;*([^;]+)(;.*)?$"
            target_label  = "instance"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_version"]
            target_label = "version"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_component", "__meta_kubernetes_pod_label_component"]
            regex         = "^;*([^;]+)(;.*)?$"
            target_label  = "component"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_node_name"]
            target_label  = "node_name"
          }

          rule {
            source_labels = ["__meta_kubernetes_namespace"]
            target_label  = "namespace"
          }

          rule {
            source_labels = ["namespace", "app"]
            separator     = "/"
            target_label  = "job"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_name"]
            target_label  = "pod"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_container_name"]
            target_label  = "container"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
            separator     = "/"
            target_label  = "__path__"
            replacement   = "/var/log/pods/*$1/*.log"
          }

          rule {
            source_labels = ["__meta_kubernetes_pod_annotationpresent_kubernetes_io_config_hash", "__meta_kubernetes_pod_annotation_kubernetes_io_config_hash", "__meta_kubernetes_pod_container_name"]
            separator     = "/"
            regex         = "true/(.*)"
            target_label  = "__path__"
            replacement   = "/var/log/pods/*$1/*.log"
          }
        }

        loki.source.kubernetes "pod_logs" {
          targets = discovery.relabel.filtered_pods.output
          forward_to = [loki.process.tenant_logs.receiver]
        }

        loki.process "tenant_logs" {
          // ========== CRI parsing
          // raw format: {"log":"Hello World\n","stream":"stdout","time":"2025-08-14T10:59:00.123456789Z"}
          stage.cri {}

          // ========== Drop noisy system logs
          stage.drop {
            expression = "unable to retrieve container logs for containerd://"
          }

          {{- if not (empty .Values.staticLabels) }}
          // ========== Example - Optional static Labels
          stage.static_labels {
            values = {
              {{- range $key, $value := .Values.staticLabels }}
              {{ $key }} = "{{ $value }}",
              {{- end }}
            }
          }
          {{- end }}

          // ========== Cardinality optimization
          stage.label_keep {
            // Optimisation: remove all labels except those listed
            // Performance: Drastically reduces Loki cardinality
            // Rule: Keep only labels used in your queries
            values = [
              "tenant",
              "retention_policy",
              "environment",
              "environment_type",
              "app",
              "file",
              "instance",
              "version",
              "component",
              "pod",
              "container",
              "node_name",
              "namespace",
              "job",
              {{- range $key, $value := .Values.staticLabels }}
              "{{ $key }}",
              {{- end }}
            ]
          }

          // ========== Strip ANSI color codes
          stage.decolorize {}

          // ========== Tenant assignment
          stage.tenant {
            // Use "tenant" label previously created
            // Alloy will add Header X-Scope-OrgID with value of 'radiantlogic.io/environment' label
            source = "tenant"
          }

          // ========== Final message
          stage.output {
            // Effective log text (without JSON metadata)
            source = "message"
          }

          forward_to = [loki.write.centralized.receiver]
        }

        loki.write "centralized" {
          endpoint {
            url = {{ .Values.loki.url | quote}}

            // Wait before sending batch
            batch_wait = "1s"

            // Max batch size (bytes)
            batch_size = "1MiB"

            // Retry configuration - if Loki is down or overloaded
            // Initial backoff time between retries
            min_backoff_period = "100ms"

            // Maximum backoff time between retries
            max_backoff_period = "5m"

            // Max number of retries
            max_backoff_retries = 10

            // Timeout requte HTTP
            remote_timeout = "10s"
          }

          // Limit concurrent streams
          max_streams = 5000
        }
